{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, nibabel as nib, numpy as np\n",
    "sys.path.insert(0, 'core/')\n",
    "from epi import  data_prep_ml\n",
    "from utils import imask_ut\n",
    "from denoiser import cnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.draw import disk\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askdirectory\n",
    "Tk().withdraw() #hide the tk root window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user specify data directory\n",
    "mainpath = askdirectory(title = 'Path to Phantom Data')\n",
    "\n",
    "# make output directory\n",
    "outpath = mainpath + '/CNN Trained'\n",
    "os.makedirs(outpath, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_ts = mainpath + '/Extracted Time Series/groundtruth.nii' # Path of the ground truth in nifti format.\n",
    "measured_fmri_ts = mainpath + '/Extracted Time Series/measured.nii' # Path of the extracted measured fMRI time series in nifti format. \n",
    "masks = mainpath + '/Extracted Time Series/masks.nii' # Path of the saved masks of the extracted slices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Output Files - Trained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = outpath + \"/save_ml.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Before CNN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs no input if using the standard motion sequences preprogrammed for BrainDancer. If using custom sequences, provide the number of moving volumes to the data_prep_ml function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_fmri = nib.load(measured_fmri_ts)\n",
    "ground_truth = nib.load(ground_truth_ts)\n",
    "imask = nib.load(masks)\n",
    "imask_utils = imask_ut(imask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stack_scn refers to the stack of measured fMRI time series\n",
    "## stack_sim refers to the stack of ground truth time series\n",
    "stack_scn, stack_sim, noise, stack_scn_flip, stack_sim_flip, noise_flip = data_prep_ml(ground_truth,measured_fmri,imask_utils,1,600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 250 # Enter the number of epochs for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 600, 1)]          0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 600, 18)           180       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 600, 18)           0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 600, 18)           2934      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 600, 18)          72        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 600, 18)           0         \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 600, 18)           2934      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 600, 18)          72        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 600, 18)           0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 600, 18)           2934      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 600, 18)          72        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 600, 18)           0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 600, 18)           2934      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 600, 18)          72        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 600, 18)           0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 600, 18)           2934      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 600, 18)          72        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 600, 18)           0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 600, 18)           2934      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 600, 18)          72        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 600, 18)           0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 600, 18)           0         \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 600, 1)            163       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,379\n",
      "Trainable params: 18,163\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 22:21:04.175662: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-26 22:21:04.832102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - ETA: 0s - loss: -0.0025 - custom_loss: -0.0025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 22:21:09.507895: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_custom_loss improved from inf to -0.00004, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 6s 20ms/step - loss: -0.0025 - custom_loss: -0.0025 - val_loss: -3.9012e-05 - val_custom_loss: -3.9997e-05\n",
      "Epoch 2/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0039 - custom_loss: -0.0039\n",
      "Epoch 2: val_custom_loss improved from -0.00004 to -0.00147, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0042 - custom_loss: -0.0042 - val_loss: -0.0015 - val_custom_loss: -0.0015\n",
      "Epoch 3/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0088 - custom_loss: -0.0088\n",
      "Epoch 3: val_custom_loss improved from -0.00147 to -0.00618, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0088 - custom_loss: -0.0088 - val_loss: -0.0061 - val_custom_loss: -0.0062\n",
      "Epoch 4/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0094 - custom_loss: -0.0094\n",
      "Epoch 4: val_custom_loss did not improve from -0.00618\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0096 - custom_loss: -0.0096 - val_loss: 0.0054 - val_custom_loss: 0.0052\n",
      "Epoch 5/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0119 - custom_loss: -0.0119\n",
      "Epoch 5: val_custom_loss did not improve from -0.00618\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0118 - custom_loss: -0.0118 - val_loss: 0.0042 - val_custom_loss: 0.0041\n",
      "Epoch 6/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0131 - custom_loss: -0.0131\n",
      "Epoch 6: val_custom_loss improved from -0.00618 to -0.00765, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0135 - custom_loss: -0.0135 - val_loss: -0.0075 - val_custom_loss: -0.0076\n",
      "Epoch 7/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0158 - custom_loss: -0.0158\n",
      "Epoch 7: val_custom_loss improved from -0.00765 to -0.01470, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0158 - custom_loss: -0.0158 - val_loss: -0.0144 - val_custom_loss: -0.0147\n",
      "Epoch 8/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0153 - custom_loss: -0.0153\n",
      "Epoch 8: val_custom_loss did not improve from -0.01470\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0157 - custom_loss: -0.0157 - val_loss: -0.0120 - val_custom_loss: -0.0122\n",
      "Epoch 9/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0142 - custom_loss: -0.0142\n",
      "Epoch 9: val_custom_loss did not improve from -0.01470\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0142 - custom_loss: -0.0142 - val_loss: 0.0056 - val_custom_loss: 0.0053\n",
      "Epoch 10/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0186 - custom_loss: -0.0186\n",
      "Epoch 10: val_custom_loss did not improve from -0.01470\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0185 - custom_loss: -0.0185 - val_loss: -0.0119 - val_custom_loss: -0.0121\n",
      "Epoch 11/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0200 - custom_loss: -0.0200\n",
      "Epoch 11: val_custom_loss improved from -0.01470 to -0.01726, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0197 - custom_loss: -0.0197 - val_loss: -0.0168 - val_custom_loss: -0.0173\n",
      "Epoch 12/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0150 - custom_loss: -0.0150\n",
      "Epoch 12: val_custom_loss did not improve from -0.01726\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0150 - custom_loss: -0.0150 - val_loss: -0.0136 - val_custom_loss: -0.0138\n",
      "Epoch 13/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0182 - custom_loss: -0.0182\n",
      "Epoch 13: val_custom_loss did not improve from -0.01726\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0182 - custom_loss: -0.0182 - val_loss: -0.0167 - val_custom_loss: -0.0172\n",
      "Epoch 14/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0222 - custom_loss: -0.0222\n",
      "Epoch 14: val_custom_loss did not improve from -0.01726\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0222 - custom_loss: -0.0222 - val_loss: -0.0108 - val_custom_loss: -0.0111\n",
      "Epoch 15/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0234 - custom_loss: -0.0234\n",
      "Epoch 15: val_custom_loss did not improve from -0.01726\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0234 - custom_loss: -0.0234 - val_loss: -0.0078 - val_custom_loss: -0.0082\n",
      "Epoch 16/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0232 - custom_loss: -0.0232\n",
      "Epoch 16: val_custom_loss improved from -0.01726 to -0.01899, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0233 - custom_loss: -0.0233 - val_loss: -0.0186 - val_custom_loss: -0.0190\n",
      "Epoch 17/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0173 - custom_loss: -0.0173\n",
      "Epoch 17: val_custom_loss did not improve from -0.01899\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0169 - custom_loss: -0.0169 - val_loss: 0.0409 - val_custom_loss: 0.0400\n",
      "Epoch 18/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0199 - custom_loss: -0.0199\n",
      "Epoch 18: val_custom_loss did not improve from -0.01899\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0201 - custom_loss: -0.0201 - val_loss: -0.0061 - val_custom_loss: -0.0065\n",
      "Epoch 19/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0227 - custom_loss: -0.0227\n",
      "Epoch 19: val_custom_loss did not improve from -0.01899\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0225 - custom_loss: -0.0225 - val_loss: 0.0149 - val_custom_loss: 0.0145\n",
      "Epoch 20/250\n",
      "106/110 [===========================>..] - ETA: 0s - loss: -0.0241 - custom_loss: -0.0241\n",
      "Epoch 20: val_custom_loss did not improve from -0.01899\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0243 - custom_loss: -0.0243 - val_loss: -0.0157 - val_custom_loss: -0.0161\n",
      "Epoch 21/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0244 - custom_loss: -0.0244\n",
      "Epoch 21: val_custom_loss did not improve from -0.01899\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0256 - custom_loss: -0.0256 - val_loss: -0.0128 - val_custom_loss: -0.0133\n",
      "Epoch 22/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0249 - custom_loss: -0.0249\n",
      "Epoch 22: val_custom_loss did not improve from -0.01899\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0264 - custom_loss: -0.0264 - val_loss: 0.0367 - val_custom_loss: 0.0358\n",
      "Epoch 23/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0167 - custom_loss: -0.0167\n",
      "Epoch 23: val_custom_loss did not improve from -0.01899\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0167 - custom_loss: -0.0167 - val_loss: -0.0136 - val_custom_loss: -0.0141\n",
      "Epoch 24/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0155 - custom_loss: -0.0155\n",
      "Epoch 24: val_custom_loss improved from -0.01899 to -0.02288, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0151 - custom_loss: -0.0151 - val_loss: -0.0224 - val_custom_loss: -0.0229\n",
      "Epoch 25/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0220 - custom_loss: -0.0220\n",
      "Epoch 25: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0215 - custom_loss: -0.0215 - val_loss: -8.2154e-04 - val_custom_loss: -0.0015\n",
      "Epoch 26/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0195 - custom_loss: -0.0195\n",
      "Epoch 26: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0195 - custom_loss: -0.0195 - val_loss: -0.0177 - val_custom_loss: -0.0182\n",
      "Epoch 27/250\n",
      "106/110 [===========================>..] - ETA: 0s - loss: -0.0264 - custom_loss: -0.0264\n",
      "Epoch 27: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0249 - custom_loss: -0.0249 - val_loss: -0.0191 - val_custom_loss: -0.0197\n",
      "Epoch 28/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0226 - custom_loss: -0.0226\n",
      "Epoch 28: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0232 - custom_loss: -0.0232 - val_loss: 0.0642 - val_custom_loss: 0.0634\n",
      "Epoch 29/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0244 - custom_loss: -0.0244\n",
      "Epoch 29: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0237 - custom_loss: -0.0237 - val_loss: 0.0214 - val_custom_loss: 0.0206\n",
      "Epoch 30/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0217 - custom_loss: -0.0217\n",
      "Epoch 30: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0223 - custom_loss: -0.0223 - val_loss: -0.0221 - val_custom_loss: -0.0225\n",
      "Epoch 31/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0224 - custom_loss: -0.0224\n",
      "Epoch 31: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0224 - custom_loss: -0.0224 - val_loss: -0.0153 - val_custom_loss: -0.0159\n",
      "Epoch 32/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0258 - custom_loss: -0.0258\n",
      "Epoch 32: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0264 - custom_loss: -0.0264 - val_loss: -0.0015 - val_custom_loss: -0.0021\n",
      "Epoch 33/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0186 - custom_loss: -0.0186\n",
      "Epoch 33: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0201 - custom_loss: -0.0201 - val_loss: -0.0206 - val_custom_loss: -0.0209\n",
      "Epoch 34/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0294 - custom_loss: -0.0294\n",
      "Epoch 34: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0299 - custom_loss: -0.0299 - val_loss: -0.0112 - val_custom_loss: -0.0117\n",
      "Epoch 35/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0249 - custom_loss: -0.0249\n",
      "Epoch 35: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0249 - custom_loss: -0.0249 - val_loss: 0.0116 - val_custom_loss: 0.0109\n",
      "Epoch 36/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0244 - custom_loss: -0.0244\n",
      "Epoch 36: val_custom_loss did not improve from -0.02288\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0246 - custom_loss: -0.0246 - val_loss: -0.0044 - val_custom_loss: -0.0049\n",
      "Epoch 37/250\n",
      "106/110 [===========================>..] - ETA: 0s - loss: -0.0225 - custom_loss: -0.0225\n",
      "Epoch 37: val_custom_loss improved from -0.02288 to -0.02298, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0225 - custom_loss: -0.0225 - val_loss: -0.0224 - val_custom_loss: -0.0230\n",
      "Epoch 38/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0241 - custom_loss: -0.0241\n",
      "Epoch 38: val_custom_loss improved from -0.02298 to -0.02423, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0241 - custom_loss: -0.0241 - val_loss: -0.0237 - val_custom_loss: -0.0242\n",
      "Epoch 39/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0285 - custom_loss: -0.0285\n",
      "Epoch 39: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0291 - custom_loss: -0.0291 - val_loss: 0.0046 - val_custom_loss: 0.0040\n",
      "Epoch 40/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0229 - custom_loss: -0.0229\n",
      "Epoch 40: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0235 - custom_loss: -0.0235 - val_loss: 0.0171 - val_custom_loss: 0.0165\n",
      "Epoch 41/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0246 - custom_loss: -0.0246\n",
      "Epoch 41: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0249 - custom_loss: -0.0249 - val_loss: -0.0144 - val_custom_loss: -0.0150\n",
      "Epoch 42/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0283 - custom_loss: -0.0283\n",
      "Epoch 42: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 18ms/step - loss: -0.0283 - custom_loss: -0.0283 - val_loss: -0.0170 - val_custom_loss: -0.0174\n",
      "Epoch 43/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0236 - custom_loss: -0.0236\n",
      "Epoch 43: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0243 - custom_loss: -0.0243 - val_loss: -0.0146 - val_custom_loss: -0.0150\n",
      "Epoch 44/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0200 - custom_loss: -0.0200\n",
      "Epoch 44: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 18ms/step - loss: -0.0200 - custom_loss: -0.0200 - val_loss: 0.0181 - val_custom_loss: 0.0172\n",
      "Epoch 45/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0255 - custom_loss: -0.0255\n",
      "Epoch 45: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 18ms/step - loss: -0.0255 - custom_loss: -0.0255 - val_loss: 0.0179 - val_custom_loss: 0.0171\n",
      "Epoch 46/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0232 - custom_loss: -0.0232\n",
      "Epoch 46: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0228 - custom_loss: -0.0228 - val_loss: 0.0498 - val_custom_loss: 0.0489\n",
      "Epoch 47/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0231 - custom_loss: -0.0231\n",
      "Epoch 47: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0231 - custom_loss: -0.0231 - val_loss: 0.0466 - val_custom_loss: 0.0455\n",
      "Epoch 48/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0188 - custom_loss: -0.0188\n",
      "Epoch 48: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0188 - custom_loss: -0.0188 - val_loss: 0.0533 - val_custom_loss: 0.0524\n",
      "Epoch 49/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0244 - custom_loss: -0.0244\n",
      "Epoch 49: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0243 - custom_loss: -0.0243 - val_loss: 0.0050 - val_custom_loss: 0.0045\n",
      "Epoch 50/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0293 - custom_loss: -0.0293\n",
      "Epoch 50: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0286 - custom_loss: -0.0286 - val_loss: -0.0173 - val_custom_loss: -0.0177\n",
      "Epoch 51/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0224 - custom_loss: -0.0224\n",
      "Epoch 51: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 20ms/step - loss: -0.0230 - custom_loss: -0.0230 - val_loss: 0.0306 - val_custom_loss: 0.0300\n",
      "Epoch 52/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0338 - custom_loss: -0.0338\n",
      "Epoch 52: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0342 - custom_loss: -0.0342 - val_loss: 0.0224 - val_custom_loss: 0.0216\n",
      "Epoch 53/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0312 - custom_loss: -0.0312\n",
      "Epoch 53: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0312 - custom_loss: -0.0312 - val_loss: 0.0743 - val_custom_loss: 0.0731\n",
      "Epoch 54/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0252 - custom_loss: -0.0252\n",
      "Epoch 54: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0252 - custom_loss: -0.0252 - val_loss: 0.0999 - val_custom_loss: 0.0988\n",
      "Epoch 55/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0308 - custom_loss: -0.0308\n",
      "Epoch 55: val_custom_loss did not improve from -0.02423\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0313 - custom_loss: -0.0313 - val_loss: 0.0454 - val_custom_loss: 0.0445\n",
      "Epoch 56/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0232 - custom_loss: -0.0232\n",
      "Epoch 56: val_custom_loss improved from -0.02423 to -0.02432, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0231 - custom_loss: -0.0231 - val_loss: -0.0239 - val_custom_loss: -0.0243\n",
      "Epoch 57/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0224 - custom_loss: -0.0224\n",
      "Epoch 57: val_custom_loss did not improve from -0.02432\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0230 - custom_loss: -0.0230 - val_loss: 0.0845 - val_custom_loss: 0.0834\n",
      "Epoch 58/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0324 - custom_loss: -0.0324\n",
      "Epoch 58: val_custom_loss did not improve from -0.02432\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0309 - custom_loss: -0.0309 - val_loss: 0.0312 - val_custom_loss: 0.0305\n",
      "Epoch 59/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0282 - custom_loss: -0.0282\n",
      "Epoch 59: val_custom_loss did not improve from -0.02432\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0290 - custom_loss: -0.0290 - val_loss: 0.1219 - val_custom_loss: 0.1205\n",
      "Epoch 60/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0277 - custom_loss: -0.0277\n",
      "Epoch 60: val_custom_loss did not improve from -0.02432\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0284 - custom_loss: -0.0284 - val_loss: 0.0177 - val_custom_loss: 0.0168\n",
      "Epoch 61/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0297 - custom_loss: -0.0297\n",
      "Epoch 61: val_custom_loss did not improve from -0.02432\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0292 - custom_loss: -0.0292 - val_loss: 0.0150 - val_custom_loss: 0.0141\n",
      "Epoch 62/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0340 - custom_loss: -0.0340\n",
      "Epoch 62: val_custom_loss did not improve from -0.02432\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0343 - custom_loss: -0.0343 - val_loss: 4.3086e-04 - val_custom_loss: -3.4085e-04\n",
      "Epoch 63/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0341 - custom_loss: -0.0341\n",
      "Epoch 63: val_custom_loss improved from -0.02432 to -0.02475, saving model to /Users/theok/Desktop/Git/Phantom dataset/CNN Trained/save_ml.h5\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0339 - custom_loss: -0.0339 - val_loss: -0.0241 - val_custom_loss: -0.0247\n",
      "Epoch 64/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0274 - custom_loss: -0.0274\n",
      "Epoch 64: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0267 - custom_loss: -0.0267 - val_loss: -1.2090e-04 - val_custom_loss: -7.5840e-04\n",
      "Epoch 65/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0311 - custom_loss: -0.0311\n",
      "Epoch 65: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0316 - custom_loss: -0.0316 - val_loss: -0.0216 - val_custom_loss: -0.0222\n",
      "Epoch 66/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0322 - custom_loss: -0.0322\n",
      "Epoch 66: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0325 - custom_loss: -0.0325 - val_loss: 0.0319 - val_custom_loss: 0.0311\n",
      "Epoch 67/250\n",
      "106/110 [===========================>..] - ETA: 0s - loss: -0.0384 - custom_loss: -0.0384\n",
      "Epoch 67: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0368 - custom_loss: -0.0368 - val_loss: -0.0151 - val_custom_loss: -0.0157\n",
      "Epoch 68/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0266 - custom_loss: -0.0266\n",
      "Epoch 68: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 14ms/step - loss: -0.0270 - custom_loss: -0.0270 - val_loss: 0.1242 - val_custom_loss: 0.1228\n",
      "Epoch 69/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0347 - custom_loss: -0.0347\n",
      "Epoch 69: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0359 - custom_loss: -0.0359 - val_loss: -0.0182 - val_custom_loss: -0.0188\n",
      "Epoch 70/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0270 - custom_loss: -0.0270\n",
      "Epoch 70: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0273 - custom_loss: -0.0273 - val_loss: 0.1037 - val_custom_loss: 0.1024\n",
      "Epoch 71/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0324 - custom_loss: -0.0324\n",
      "Epoch 71: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0322 - custom_loss: -0.0322 - val_loss: 0.0303 - val_custom_loss: 0.0295\n",
      "Epoch 72/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0399 - custom_loss: -0.0399\n",
      "Epoch 72: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0402 - custom_loss: -0.0402 - val_loss: -0.0121 - val_custom_loss: -0.0130\n",
      "Epoch 73/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0289 - custom_loss: -0.0289\n",
      "Epoch 73: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0290 - custom_loss: -0.0290 - val_loss: -0.0080 - val_custom_loss: -0.0084\n",
      "Epoch 74/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0339 - custom_loss: -0.0339\n",
      "Epoch 74: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0339 - custom_loss: -0.0339 - val_loss: -0.0065 - val_custom_loss: -0.0071\n",
      "Epoch 75/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0286 - custom_loss: -0.0286\n",
      "Epoch 75: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 23ms/step - loss: -0.0274 - custom_loss: -0.0274 - val_loss: -0.0221 - val_custom_loss: -0.0227\n",
      "Epoch 76/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0342 - custom_loss: -0.0342\n",
      "Epoch 76: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0348 - custom_loss: -0.0348 - val_loss: 0.0082 - val_custom_loss: 0.0072\n",
      "Epoch 77/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0361 - custom_loss: -0.0361\n",
      "Epoch 77: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0357 - custom_loss: -0.0357 - val_loss: -0.0230 - val_custom_loss: -0.0236\n",
      "Epoch 78/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0362 - custom_loss: -0.0362\n",
      "Epoch 78: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0364 - custom_loss: -0.0364 - val_loss: -0.0077 - val_custom_loss: -0.0083\n",
      "Epoch 79/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0335 - custom_loss: -0.0335\n",
      "Epoch 79: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0341 - custom_loss: -0.0341 - val_loss: 0.1419 - val_custom_loss: 0.1402\n",
      "Epoch 80/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0292 - custom_loss: -0.0292\n",
      "Epoch 80: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0291 - custom_loss: -0.0291 - val_loss: -0.0157 - val_custom_loss: -0.0164\n",
      "Epoch 81/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0290 - custom_loss: -0.0290\n",
      "Epoch 81: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0291 - custom_loss: -0.0291 - val_loss: -0.0096 - val_custom_loss: -0.0102\n",
      "Epoch 82/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0297 - custom_loss: -0.0297\n",
      "Epoch 82: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0308 - custom_loss: -0.0308 - val_loss: 0.0096 - val_custom_loss: 0.0089\n",
      "Epoch 83/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0278 - custom_loss: -0.0278\n",
      "Epoch 83: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0278 - custom_loss: -0.0278 - val_loss: 0.0455 - val_custom_loss: 0.0447\n",
      "Epoch 84/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0318 - custom_loss: -0.0318\n",
      "Epoch 84: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0309 - custom_loss: -0.0309 - val_loss: -0.0195 - val_custom_loss: -0.0200\n",
      "Epoch 85/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0341 - custom_loss: -0.0341\n",
      "Epoch 85: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0341 - custom_loss: -0.0341 - val_loss: 0.0015 - val_custom_loss: 6.4008e-04\n",
      "Epoch 86/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0349 - custom_loss: -0.0349\n",
      "Epoch 86: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0348 - custom_loss: -0.0348 - val_loss: 0.1180 - val_custom_loss: 0.1166\n",
      "Epoch 87/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0291 - custom_loss: -0.0291\n",
      "Epoch 87: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0275 - custom_loss: -0.0275 - val_loss: 0.0239 - val_custom_loss: 0.0233\n",
      "Epoch 88/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0347 - custom_loss: -0.0347\n",
      "Epoch 88: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0350 - custom_loss: -0.0350 - val_loss: -0.0193 - val_custom_loss: -0.0197\n",
      "Epoch 89/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0370 - custom_loss: -0.0370\n",
      "Epoch 89: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0381 - custom_loss: -0.0381 - val_loss: 0.0643 - val_custom_loss: 0.0632\n",
      "Epoch 90/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0213 - custom_loss: -0.0213\n",
      "Epoch 90: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0213 - custom_loss: -0.0213 - val_loss: 0.0799 - val_custom_loss: 0.0788\n",
      "Epoch 91/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0336 - custom_loss: -0.0336\n",
      "Epoch 91: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0336 - custom_loss: -0.0336 - val_loss: 0.0101 - val_custom_loss: 0.0092\n",
      "Epoch 92/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0394 - custom_loss: -0.0394\n",
      "Epoch 92: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0383 - custom_loss: -0.0383 - val_loss: 0.0087 - val_custom_loss: 0.0076\n",
      "Epoch 93/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0424 - custom_loss: -0.0424\n",
      "Epoch 93: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0418 - custom_loss: -0.0418 - val_loss: -0.0207 - val_custom_loss: -0.0213\n",
      "Epoch 94/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0403 - custom_loss: -0.0403\n",
      "Epoch 94: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0395 - custom_loss: -0.0395 - val_loss: 0.0044 - val_custom_loss: 0.0038\n",
      "Epoch 95/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0328 - custom_loss: -0.0328\n",
      "Epoch 95: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0328 - custom_loss: -0.0328 - val_loss: 0.1930 - val_custom_loss: 0.1909\n",
      "Epoch 96/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0365 - custom_loss: -0.0365\n",
      "Epoch 96: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0365 - custom_loss: -0.0365 - val_loss: 0.0798 - val_custom_loss: 0.0781\n",
      "Epoch 97/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0346 - custom_loss: -0.0346\n",
      "Epoch 97: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0343 - custom_loss: -0.0343 - val_loss: 0.1461 - val_custom_loss: 0.1444\n",
      "Epoch 98/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0307 - custom_loss: -0.0307\n",
      "Epoch 98: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0314 - custom_loss: -0.0314 - val_loss: 0.1592 - val_custom_loss: 0.1574\n",
      "Epoch 99/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0403 - custom_loss: -0.0403\n",
      "Epoch 99: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0403 - custom_loss: -0.0403 - val_loss: -0.0066 - val_custom_loss: -0.0073\n",
      "Epoch 100/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0349 - custom_loss: -0.0349\n",
      "Epoch 100: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0349 - custom_loss: -0.0349 - val_loss: 0.0289 - val_custom_loss: 0.0281\n",
      "Epoch 101/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0407 - custom_loss: -0.0407\n",
      "Epoch 101: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0422 - custom_loss: -0.0422 - val_loss: 0.1868 - val_custom_loss: 0.1846\n",
      "Epoch 102/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0382 - custom_loss: -0.0382\n",
      "Epoch 102: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0382 - custom_loss: -0.0382 - val_loss: 0.0309 - val_custom_loss: 0.0301\n",
      "Epoch 103/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0345 - custom_loss: -0.0345\n",
      "Epoch 103: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0342 - custom_loss: -0.0342 - val_loss: 0.0491 - val_custom_loss: 0.0481\n",
      "Epoch 104/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0411 - custom_loss: -0.0411\n",
      "Epoch 104: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0417 - custom_loss: -0.0417 - val_loss: -0.0175 - val_custom_loss: -0.0184\n",
      "Epoch 105/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0379 - custom_loss: -0.0379\n",
      "Epoch 105: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0393 - custom_loss: -0.0393 - val_loss: 0.0378 - val_custom_loss: 0.0368\n",
      "Epoch 106/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0477 - custom_loss: -0.0477\n",
      "Epoch 106: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0487 - custom_loss: -0.0487 - val_loss: -0.0099 - val_custom_loss: -0.0105\n",
      "Epoch 107/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0433 - custom_loss: -0.0433\n",
      "Epoch 107: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0438 - custom_loss: -0.0438 - val_loss: 0.0597 - val_custom_loss: 0.0586\n",
      "Epoch 108/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0328 - custom_loss: -0.0328\n",
      "Epoch 108: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0328 - custom_loss: -0.0328 - val_loss: 0.0134 - val_custom_loss: 0.0128\n",
      "Epoch 109/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0475 - custom_loss: -0.0475\n",
      "Epoch 109: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0469 - custom_loss: -0.0469 - val_loss: 0.0659 - val_custom_loss: 0.0646\n",
      "Epoch 110/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0456 - custom_loss: -0.0456\n",
      "Epoch 110: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0458 - custom_loss: -0.0458 - val_loss: 0.1355 - val_custom_loss: 0.1337\n",
      "Epoch 111/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0438 - custom_loss: -0.0438\n",
      "Epoch 111: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0438 - custom_loss: -0.0438 - val_loss: -0.0109 - val_custom_loss: -0.0117\n",
      "Epoch 112/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0418 - custom_loss: -0.0418\n",
      "Epoch 112: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0409 - custom_loss: -0.0409 - val_loss: 0.1837 - val_custom_loss: 0.1815\n",
      "Epoch 113/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0378 - custom_loss: -0.0378\n",
      "Epoch 113: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0378 - custom_loss: -0.0378 - val_loss: -0.0154 - val_custom_loss: -0.0159\n",
      "Epoch 114/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0402 - custom_loss: -0.0402\n",
      "Epoch 114: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0397 - custom_loss: -0.0397 - val_loss: -0.0112 - val_custom_loss: -0.0118\n",
      "Epoch 115/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0437 - custom_loss: -0.0437\n",
      "Epoch 115: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0433 - custom_loss: -0.0433 - val_loss: 0.1615 - val_custom_loss: 0.1594\n",
      "Epoch 116/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0408 - custom_loss: -0.0408\n",
      "Epoch 116: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0421 - custom_loss: -0.0421 - val_loss: -0.0143 - val_custom_loss: -0.0149\n",
      "Epoch 117/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0502 - custom_loss: -0.0502\n",
      "Epoch 117: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0499 - custom_loss: -0.0499 - val_loss: -0.0060 - val_custom_loss: -0.0070\n",
      "Epoch 118/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0406 - custom_loss: -0.0406\n",
      "Epoch 118: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0401 - custom_loss: -0.0401 - val_loss: 0.1379 - val_custom_loss: 0.1362\n",
      "Epoch 119/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0476 - custom_loss: -0.0476\n",
      "Epoch 119: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0491 - custom_loss: -0.0491 - val_loss: 0.0732 - val_custom_loss: 0.0719\n",
      "Epoch 120/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0387 - custom_loss: -0.0387\n",
      "Epoch 120: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0395 - custom_loss: -0.0395 - val_loss: 0.0671 - val_custom_loss: 0.0657\n",
      "Epoch 121/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0467 - custom_loss: -0.0467\n",
      "Epoch 121: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0451 - custom_loss: -0.0451 - val_loss: 0.0610 - val_custom_loss: 0.0598\n",
      "Epoch 122/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0460 - custom_loss: -0.0460\n",
      "Epoch 122: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0451 - custom_loss: -0.0451 - val_loss: 0.0011 - val_custom_loss: 1.6920e-04\n",
      "Epoch 123/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0490 - custom_loss: -0.0490\n",
      "Epoch 123: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0482 - custom_loss: -0.0482 - val_loss: -0.0013 - val_custom_loss: -0.0025\n",
      "Epoch 124/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0532 - custom_loss: -0.0532\n",
      "Epoch 124: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0532 - custom_loss: -0.0532 - val_loss: -0.0114 - val_custom_loss: -0.0121\n",
      "Epoch 125/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0455 - custom_loss: -0.0455\n",
      "Epoch 125: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0447 - custom_loss: -0.0447 - val_loss: 0.0071 - val_custom_loss: 0.0064\n",
      "Epoch 126/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0473 - custom_loss: -0.0473\n",
      "Epoch 126: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0486 - custom_loss: -0.0486 - val_loss: 0.0441 - val_custom_loss: 0.0430\n",
      "Epoch 127/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0541 - custom_loss: -0.0541\n",
      "Epoch 127: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0547 - custom_loss: -0.0547 - val_loss: 0.0130 - val_custom_loss: 0.0119\n",
      "Epoch 128/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0412 - custom_loss: -0.0412\n",
      "Epoch 128: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0412 - custom_loss: -0.0412 - val_loss: -0.0102 - val_custom_loss: -0.0109\n",
      "Epoch 129/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0536 - custom_loss: -0.0536\n",
      "Epoch 129: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0518 - custom_loss: -0.0518 - val_loss: -0.0120 - val_custom_loss: -0.0126\n",
      "Epoch 130/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0480 - custom_loss: -0.0480\n",
      "Epoch 130: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0483 - custom_loss: -0.0483 - val_loss: 0.1024 - val_custom_loss: 0.1008\n",
      "Epoch 131/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0422 - custom_loss: -0.0422\n",
      "Epoch 131: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0436 - custom_loss: -0.0436 - val_loss: -0.0071 - val_custom_loss: -0.0076\n",
      "Epoch 132/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0476 - custom_loss: -0.0476\n",
      "Epoch 132: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0469 - custom_loss: -0.0469 - val_loss: 0.0072 - val_custom_loss: 0.0063\n",
      "Epoch 133/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0474 - custom_loss: -0.0474\n",
      "Epoch 133: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0482 - custom_loss: -0.0482 - val_loss: 0.0615 - val_custom_loss: 0.0604\n",
      "Epoch 134/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0350 - custom_loss: -0.0350\n",
      "Epoch 134: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0352 - custom_loss: -0.0352 - val_loss: 0.2251 - val_custom_loss: 0.2225\n",
      "Epoch 135/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0425 - custom_loss: -0.0425\n",
      "Epoch 135: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0423 - custom_loss: -0.0423 - val_loss: 0.1208 - val_custom_loss: 0.1192\n",
      "Epoch 136/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0554 - custom_loss: -0.0554\n",
      "Epoch 136: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0549 - custom_loss: -0.0549 - val_loss: 0.1195 - val_custom_loss: 0.1178\n",
      "Epoch 137/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0449 - custom_loss: -0.0449\n",
      "Epoch 137: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0464 - custom_loss: -0.0464 - val_loss: 0.0098 - val_custom_loss: 0.0089\n",
      "Epoch 138/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0533 - custom_loss: -0.0533\n",
      "Epoch 138: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0536 - custom_loss: -0.0536 - val_loss: 0.0043 - val_custom_loss: 0.0035\n",
      "Epoch 139/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0539 - custom_loss: -0.0539\n",
      "Epoch 139: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0537 - custom_loss: -0.0537 - val_loss: 0.0818 - val_custom_loss: 0.0805\n",
      "Epoch 140/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0527 - custom_loss: -0.0527\n",
      "Epoch 140: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0527 - custom_loss: -0.0527 - val_loss: 0.0752 - val_custom_loss: 0.0737\n",
      "Epoch 141/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0495 - custom_loss: -0.0495\n",
      "Epoch 141: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0497 - custom_loss: -0.0497 - val_loss: 0.0355 - val_custom_loss: 0.0342\n",
      "Epoch 142/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0490 - custom_loss: -0.0490\n",
      "Epoch 142: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0518 - custom_loss: -0.0518 - val_loss: 0.2390 - val_custom_loss: 0.2363\n",
      "Epoch 143/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0506 - custom_loss: -0.0506\n",
      "Epoch 143: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0506 - custom_loss: -0.0506 - val_loss: 0.1318 - val_custom_loss: 0.1300\n",
      "Epoch 144/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0555 - custom_loss: -0.0555\n",
      "Epoch 144: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0550 - custom_loss: -0.0550 - val_loss: -0.0053 - val_custom_loss: -0.0058\n",
      "Epoch 145/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0542 - custom_loss: -0.0542\n",
      "Epoch 145: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0546 - custom_loss: -0.0546 - val_loss: -0.0042 - val_custom_loss: -0.0049\n",
      "Epoch 146/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0576 - custom_loss: -0.0576\n",
      "Epoch 146: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0576 - custom_loss: -0.0576 - val_loss: 0.1759 - val_custom_loss: 0.1737\n",
      "Epoch 147/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0475 - custom_loss: -0.0475\n",
      "Epoch 147: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0483 - custom_loss: -0.0483 - val_loss: 0.0385 - val_custom_loss: 0.0374\n",
      "Epoch 148/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0583 - custom_loss: -0.0583\n",
      "Epoch 148: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0585 - custom_loss: -0.0585 - val_loss: 0.2060 - val_custom_loss: 0.2035\n",
      "Epoch 149/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0550 - custom_loss: -0.0550\n",
      "Epoch 149: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0550 - custom_loss: -0.0550 - val_loss: 0.0413 - val_custom_loss: 0.0402\n",
      "Epoch 150/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0564 - custom_loss: -0.0564\n",
      "Epoch 150: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0564 - custom_loss: -0.0564 - val_loss: 0.0059 - val_custom_loss: 0.0048\n",
      "Epoch 151/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0611 - custom_loss: -0.0611\n",
      "Epoch 151: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0607 - custom_loss: -0.0607 - val_loss: 0.0672 - val_custom_loss: 0.0659\n",
      "Epoch 152/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0467 - custom_loss: -0.0467\n",
      "Epoch 152: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0467 - custom_loss: -0.0467 - val_loss: 0.0480 - val_custom_loss: 0.0469\n",
      "Epoch 153/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0590 - custom_loss: -0.0590\n",
      "Epoch 153: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0590 - custom_loss: -0.0590 - val_loss: 0.3288 - val_custom_loss: 0.3252\n",
      "Epoch 154/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0571 - custom_loss: -0.0571\n",
      "Epoch 154: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0580 - custom_loss: -0.0580 - val_loss: -0.0039 - val_custom_loss: -0.0047\n",
      "Epoch 155/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0455 - custom_loss: -0.0455\n",
      "Epoch 155: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0452 - custom_loss: -0.0452 - val_loss: 0.1307 - val_custom_loss: 0.1289\n",
      "Epoch 156/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0501 - custom_loss: -0.0501\n",
      "Epoch 156: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0501 - custom_loss: -0.0501 - val_loss: 0.0412 - val_custom_loss: 0.0400\n",
      "Epoch 157/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0566 - custom_loss: -0.0566\n",
      "Epoch 157: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0575 - custom_loss: -0.0575 - val_loss: 0.0041 - val_custom_loss: 0.0029\n",
      "Epoch 158/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0524 - custom_loss: -0.0524\n",
      "Epoch 158: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0505 - custom_loss: -0.0505 - val_loss: 0.0015 - val_custom_loss: 6.5454e-04\n",
      "Epoch 159/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0601 - custom_loss: -0.0601\n",
      "Epoch 159: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0596 - custom_loss: -0.0596 - val_loss: 0.1227 - val_custom_loss: 0.1206\n",
      "Epoch 160/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0666 - custom_loss: -0.0666\n",
      "Epoch 160: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0656 - custom_loss: -0.0656 - val_loss: 0.1142 - val_custom_loss: 0.1122\n",
      "Epoch 161/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0600 - custom_loss: -0.0600\n",
      "Epoch 161: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0575 - custom_loss: -0.0575 - val_loss: 0.0407 - val_custom_loss: 0.0394\n",
      "Epoch 162/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0632 - custom_loss: -0.0632\n",
      "Epoch 162: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0621 - custom_loss: -0.0621 - val_loss: 0.2246 - val_custom_loss: 0.2218\n",
      "Epoch 163/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0633 - custom_loss: -0.0633\n",
      "Epoch 163: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0633 - custom_loss: -0.0633 - val_loss: 0.1499 - val_custom_loss: 0.1477\n",
      "Epoch 164/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0733 - custom_loss: -0.0733\n",
      "Epoch 164: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0733 - custom_loss: -0.0733 - val_loss: 0.1731 - val_custom_loss: 0.1707\n",
      "Epoch 165/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0564 - custom_loss: -0.0564\n",
      "Epoch 165: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0567 - custom_loss: -0.0567 - val_loss: 0.0528 - val_custom_loss: 0.0517\n",
      "Epoch 166/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0573 - custom_loss: -0.0573\n",
      "Epoch 166: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0576 - custom_loss: -0.0576 - val_loss: 0.0319 - val_custom_loss: 0.0309\n",
      "Epoch 167/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0521 - custom_loss: -0.0521\n",
      "Epoch 167: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0526 - custom_loss: -0.0526 - val_loss: 0.0183 - val_custom_loss: 0.0172\n",
      "Epoch 168/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0703 - custom_loss: -0.0703\n",
      "Epoch 168: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0700 - custom_loss: -0.0700 - val_loss: 0.0182 - val_custom_loss: 0.0169\n",
      "Epoch 169/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0540 - custom_loss: -0.0540\n",
      "Epoch 169: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0540 - custom_loss: -0.0540 - val_loss: 0.1195 - val_custom_loss: 0.1177\n",
      "Epoch 170/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0697 - custom_loss: -0.0697\n",
      "Epoch 170: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0697 - custom_loss: -0.0697 - val_loss: 0.0078 - val_custom_loss: 0.0067\n",
      "Epoch 171/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0676 - custom_loss: -0.0676\n",
      "Epoch 171: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0665 - custom_loss: -0.0665 - val_loss: 0.0662 - val_custom_loss: 0.0648\n",
      "Epoch 172/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0709 - custom_loss: -0.0709\n",
      "Epoch 172: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0710 - custom_loss: -0.0710 - val_loss: 0.0054 - val_custom_loss: 0.0045\n",
      "Epoch 173/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0675 - custom_loss: -0.0675\n",
      "Epoch 173: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0664 - custom_loss: -0.0664 - val_loss: 0.1784 - val_custom_loss: 0.1761\n",
      "Epoch 174/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0653 - custom_loss: -0.0653\n",
      "Epoch 174: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0673 - custom_loss: -0.0673 - val_loss: 0.0137 - val_custom_loss: 0.0124\n",
      "Epoch 175/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0633 - custom_loss: -0.0633\n",
      "Epoch 175: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0630 - custom_loss: -0.0630 - val_loss: 0.2234 - val_custom_loss: 0.2208\n",
      "Epoch 176/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0737 - custom_loss: -0.0737\n",
      "Epoch 176: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0737 - custom_loss: -0.0737 - val_loss: 0.0233 - val_custom_loss: 0.0221\n",
      "Epoch 177/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0631 - custom_loss: -0.0631\n",
      "Epoch 177: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0611 - custom_loss: -0.0611 - val_loss: 0.1911 - val_custom_loss: 0.1885\n",
      "Epoch 178/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0719 - custom_loss: -0.0719\n",
      "Epoch 178: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0730 - custom_loss: -0.0730 - val_loss: 0.0914 - val_custom_loss: 0.0899\n",
      "Epoch 179/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0754 - custom_loss: -0.0754\n",
      "Epoch 179: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0756 - custom_loss: -0.0756 - val_loss: 0.0760 - val_custom_loss: 0.0746\n",
      "Epoch 180/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0705 - custom_loss: -0.0705\n",
      "Epoch 180: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0697 - custom_loss: -0.0697 - val_loss: 0.0292 - val_custom_loss: 0.0279\n",
      "Epoch 181/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0644 - custom_loss: -0.0644\n",
      "Epoch 181: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0634 - custom_loss: -0.0634 - val_loss: 0.0234 - val_custom_loss: 0.0221\n",
      "Epoch 182/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0744 - custom_loss: -0.0744\n",
      "Epoch 182: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0750 - custom_loss: -0.0750 - val_loss: 0.0082 - val_custom_loss: 0.0071\n",
      "Epoch 183/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0702 - custom_loss: -0.0702\n",
      "Epoch 183: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0704 - custom_loss: -0.0704 - val_loss: 0.0288 - val_custom_loss: 0.0278\n",
      "Epoch 184/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0761 - custom_loss: -0.0761\n",
      "Epoch 184: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0752 - custom_loss: -0.0752 - val_loss: 0.0445 - val_custom_loss: 0.0430\n",
      "Epoch 185/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0640 - custom_loss: -0.0640\n",
      "Epoch 185: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 16ms/step - loss: -0.0640 - custom_loss: -0.0640 - val_loss: 0.0177 - val_custom_loss: 0.0166\n",
      "Epoch 186/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0681 - custom_loss: -0.0681\n",
      "Epoch 186: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0681 - custom_loss: -0.0681 - val_loss: 0.0924 - val_custom_loss: 0.0906\n",
      "Epoch 187/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0692 - custom_loss: -0.0692\n",
      "Epoch 187: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0708 - custom_loss: -0.0708 - val_loss: 0.0200 - val_custom_loss: 0.0187\n",
      "Epoch 188/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.0747 - custom_loss: -0.0747\n",
      "Epoch 188: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0770 - custom_loss: -0.0770 - val_loss: 0.2516 - val_custom_loss: 0.2485\n",
      "Epoch 189/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0697 - custom_loss: -0.0697\n",
      "Epoch 189: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 18ms/step - loss: -0.0704 - custom_loss: -0.0704 - val_loss: 0.0225 - val_custom_loss: 0.0213\n",
      "Epoch 190/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0722 - custom_loss: -0.0722\n",
      "Epoch 190: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0719 - custom_loss: -0.0719 - val_loss: 0.0204 - val_custom_loss: 0.0194\n",
      "Epoch 191/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0804 - custom_loss: -0.0804\n",
      "Epoch 191: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0812 - custom_loss: -0.0812 - val_loss: 0.2338 - val_custom_loss: 0.2308\n",
      "Epoch 192/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0796 - custom_loss: -0.0796\n",
      "Epoch 192: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0796 - custom_loss: -0.0796 - val_loss: 0.0820 - val_custom_loss: 0.0806\n",
      "Epoch 193/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0787 - custom_loss: -0.0787\n",
      "Epoch 193: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0789 - custom_loss: -0.0789 - val_loss: 0.2494 - val_custom_loss: 0.2463\n",
      "Epoch 194/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0729 - custom_loss: -0.0729\n",
      "Epoch 194: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0717 - custom_loss: -0.0717 - val_loss: 0.0320 - val_custom_loss: 0.0307\n",
      "Epoch 195/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0798 - custom_loss: -0.0798\n",
      "Epoch 195: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0808 - custom_loss: -0.0808 - val_loss: 0.0824 - val_custom_loss: 0.0807\n",
      "Epoch 196/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0751 - custom_loss: -0.0751\n",
      "Epoch 196: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0751 - custom_loss: -0.0751 - val_loss: 0.2733 - val_custom_loss: 0.2702\n",
      "Epoch 197/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0775 - custom_loss: -0.0775\n",
      "Epoch 197: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0774 - custom_loss: -0.0774 - val_loss: 0.1708 - val_custom_loss: 0.1686\n",
      "Epoch 198/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0744 - custom_loss: -0.0744\n",
      "Epoch 198: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0750 - custom_loss: -0.0750 - val_loss: 0.3031 - val_custom_loss: 0.2996\n",
      "Epoch 199/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0834 - custom_loss: -0.0834\n",
      "Epoch 199: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0836 - custom_loss: -0.0836 - val_loss: 0.0206 - val_custom_loss: 0.0195\n",
      "Epoch 200/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0877 - custom_loss: -0.0877\n",
      "Epoch 200: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0863 - custom_loss: -0.0863 - val_loss: 0.2049 - val_custom_loss: 0.2024\n",
      "Epoch 201/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0831 - custom_loss: -0.0831\n",
      "Epoch 201: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0839 - custom_loss: -0.0839 - val_loss: 0.0722 - val_custom_loss: 0.0706\n",
      "Epoch 202/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0796 - custom_loss: -0.0796\n",
      "Epoch 202: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0796 - custom_loss: -0.0796 - val_loss: 0.0184 - val_custom_loss: 0.0172\n",
      "Epoch 203/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0694 - custom_loss: -0.0694\n",
      "Epoch 203: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0686 - custom_loss: -0.0686 - val_loss: 0.0319 - val_custom_loss: 0.0309\n",
      "Epoch 204/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0679 - custom_loss: -0.0679\n",
      "Epoch 204: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0686 - custom_loss: -0.0686 - val_loss: 0.0265 - val_custom_loss: 0.0252\n",
      "Epoch 205/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0846 - custom_loss: -0.0846\n",
      "Epoch 205: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0846 - custom_loss: -0.0846 - val_loss: 0.2108 - val_custom_loss: 0.2082\n",
      "Epoch 206/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0783 - custom_loss: -0.0783\n",
      "Epoch 206: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0783 - custom_loss: -0.0783 - val_loss: 0.0672 - val_custom_loss: 0.0658\n",
      "Epoch 207/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0852 - custom_loss: -0.0852\n",
      "Epoch 207: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0857 - custom_loss: -0.0857 - val_loss: 0.0579 - val_custom_loss: 0.0562\n",
      "Epoch 208/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0883 - custom_loss: -0.0883\n",
      "Epoch 208: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0868 - custom_loss: -0.0868 - val_loss: 0.0297 - val_custom_loss: 0.0283\n",
      "Epoch 209/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0940 - custom_loss: -0.0940\n",
      "Epoch 209: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0919 - custom_loss: -0.0919 - val_loss: 0.0940 - val_custom_loss: 0.0921\n",
      "Epoch 210/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0926 - custom_loss: -0.0926\n",
      "Epoch 210: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0927 - custom_loss: -0.0927 - val_loss: 0.0352 - val_custom_loss: 0.0338\n",
      "Epoch 211/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0821 - custom_loss: -0.0821\n",
      "Epoch 211: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0822 - custom_loss: -0.0822 - val_loss: 0.1378 - val_custom_loss: 0.1358\n",
      "Epoch 212/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0779 - custom_loss: -0.0779\n",
      "Epoch 212: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0781 - custom_loss: -0.0781 - val_loss: 0.2425 - val_custom_loss: 0.2397\n",
      "Epoch 213/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0956 - custom_loss: -0.0956\n",
      "Epoch 213: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0947 - custom_loss: -0.0947 - val_loss: 0.1133 - val_custom_loss: 0.1112\n",
      "Epoch 214/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0859 - custom_loss: -0.0859\n",
      "Epoch 214: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0869 - custom_loss: -0.0869 - val_loss: 0.0546 - val_custom_loss: 0.0529\n",
      "Epoch 215/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0808 - custom_loss: -0.0808\n",
      "Epoch 215: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0813 - custom_loss: -0.0813 - val_loss: 0.0342 - val_custom_loss: 0.0329\n",
      "Epoch 216/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0931 - custom_loss: -0.0931\n",
      "Epoch 216: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0911 - custom_loss: -0.0911 - val_loss: 0.0367 - val_custom_loss: 0.0355\n",
      "Epoch 217/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0905 - custom_loss: -0.0905\n",
      "Epoch 217: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0916 - custom_loss: -0.0916 - val_loss: 0.0528 - val_custom_loss: 0.0515\n",
      "Epoch 218/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0902 - custom_loss: -0.0902\n",
      "Epoch 218: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 20ms/step - loss: -0.0902 - custom_loss: -0.0902 - val_loss: 0.0544 - val_custom_loss: 0.0528\n",
      "Epoch 219/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0866 - custom_loss: -0.0866\n",
      "Epoch 219: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 17ms/step - loss: -0.0866 - custom_loss: -0.0866 - val_loss: 0.1018 - val_custom_loss: 0.0999\n",
      "Epoch 220/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0942 - custom_loss: -0.0942\n",
      "Epoch 220: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0899 - custom_loss: -0.0899 - val_loss: 0.2087 - val_custom_loss: 0.2060\n",
      "Epoch 221/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0974 - custom_loss: -0.0974\n",
      "Epoch 221: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0982 - custom_loss: -0.0982 - val_loss: 0.1182 - val_custom_loss: 0.1162\n",
      "Epoch 222/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0937 - custom_loss: -0.0937\n",
      "Epoch 222: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0943 - custom_loss: -0.0943 - val_loss: 0.1232 - val_custom_loss: 0.1211\n",
      "Epoch 223/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0903 - custom_loss: -0.0903\n",
      "Epoch 223: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0911 - custom_loss: -0.0911 - val_loss: 0.2022 - val_custom_loss: 0.1997\n",
      "Epoch 224/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0920 - custom_loss: -0.0920\n",
      "Epoch 224: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0917 - custom_loss: -0.0917 - val_loss: 0.0380 - val_custom_loss: 0.0368\n",
      "Epoch 225/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0952 - custom_loss: -0.0952\n",
      "Epoch 225: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0952 - custom_loss: -0.0952 - val_loss: 0.3101 - val_custom_loss: 0.3064\n",
      "Epoch 226/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0952 - custom_loss: -0.0952\n",
      "Epoch 226: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0938 - custom_loss: -0.0938 - val_loss: 0.0912 - val_custom_loss: 0.0898\n",
      "Epoch 227/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0914 - custom_loss: -0.0914\n",
      "Epoch 227: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0914 - custom_loss: -0.0914 - val_loss: 0.2721 - val_custom_loss: 0.2686\n",
      "Epoch 228/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.1050 - custom_loss: -0.1050\n",
      "Epoch 228: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1054 - custom_loss: -0.1054 - val_loss: 0.1611 - val_custom_loss: 0.1582\n",
      "Epoch 229/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0873 - custom_loss: -0.0873\n",
      "Epoch 229: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0870 - custom_loss: -0.0870 - val_loss: 0.0309 - val_custom_loss: 0.0298\n",
      "Epoch 230/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0968 - custom_loss: -0.0968\n",
      "Epoch 230: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0968 - custom_loss: -0.0968 - val_loss: 0.0379 - val_custom_loss: 0.0369\n",
      "Epoch 231/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0951 - custom_loss: -0.0951\n",
      "Epoch 231: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0954 - custom_loss: -0.0954 - val_loss: 0.0305 - val_custom_loss: 0.0293\n",
      "Epoch 232/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0975 - custom_loss: -0.0975\n",
      "Epoch 232: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0981 - custom_loss: -0.0981 - val_loss: 0.0623 - val_custom_loss: 0.0611\n",
      "Epoch 233/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.1039 - custom_loss: -0.1039\n",
      "Epoch 233: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1050 - custom_loss: -0.1050 - val_loss: 0.0994 - val_custom_loss: 0.0977\n",
      "Epoch 234/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0946 - custom_loss: -0.0946\n",
      "Epoch 234: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0945 - custom_loss: -0.0945 - val_loss: 0.3734 - val_custom_loss: 0.3694\n",
      "Epoch 235/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0872 - custom_loss: -0.0872\n",
      "Epoch 235: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0872 - custom_loss: -0.0872 - val_loss: 0.1563 - val_custom_loss: 0.1538\n",
      "Epoch 236/250\n",
      "110/110 [==============================] - ETA: 0s - loss: -0.0967 - custom_loss: -0.0967\n",
      "Epoch 236: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0967 - custom_loss: -0.0967 - val_loss: 0.0299 - val_custom_loss: 0.0288\n",
      "Epoch 237/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0854 - custom_loss: -0.0854\n",
      "Epoch 237: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0853 - custom_loss: -0.0853 - val_loss: 0.0763 - val_custom_loss: 0.0748\n",
      "Epoch 238/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.1041 - custom_loss: -0.1041\n",
      "Epoch 238: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1032 - custom_loss: -0.1032 - val_loss: 0.1606 - val_custom_loss: 0.1586\n",
      "Epoch 239/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.1023 - custom_loss: -0.1023\n",
      "Epoch 239: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1033 - custom_loss: -0.1033 - val_loss: 0.0476 - val_custom_loss: 0.0463\n",
      "Epoch 240/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0867 - custom_loss: -0.0867\n",
      "Epoch 240: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0871 - custom_loss: -0.0871 - val_loss: 0.0374 - val_custom_loss: 0.0362\n",
      "Epoch 241/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.1037 - custom_loss: -0.1037\n",
      "Epoch 241: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1039 - custom_loss: -0.1039 - val_loss: 0.0369 - val_custom_loss: 0.0356\n",
      "Epoch 242/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.1038 - custom_loss: -0.1038\n",
      "Epoch 242: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1035 - custom_loss: -0.1035 - val_loss: 0.0639 - val_custom_loss: 0.0625\n",
      "Epoch 243/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0939 - custom_loss: -0.0939\n",
      "Epoch 243: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0947 - custom_loss: -0.0947 - val_loss: 0.0596 - val_custom_loss: 0.0583\n",
      "Epoch 244/250\n",
      "107/110 [============================>.] - ETA: 0s - loss: -0.1027 - custom_loss: -0.1027\n",
      "Epoch 244: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1046 - custom_loss: -0.1046 - val_loss: 0.0652 - val_custom_loss: 0.0637\n",
      "Epoch 245/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.1074 - custom_loss: -0.1074\n",
      "Epoch 245: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1069 - custom_loss: -0.1069 - val_loss: 0.0863 - val_custom_loss: 0.0848\n",
      "Epoch 246/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.0992 - custom_loss: -0.0992\n",
      "Epoch 246: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1003 - custom_loss: -0.1003 - val_loss: 0.0759 - val_custom_loss: 0.0742\n",
      "Epoch 247/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.0984 - custom_loss: -0.0984\n",
      "Epoch 247: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.0984 - custom_loss: -0.0984 - val_loss: 0.0515 - val_custom_loss: 0.0502\n",
      "Epoch 248/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.1080 - custom_loss: -0.1080\n",
      "Epoch 248: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1089 - custom_loss: -0.1089 - val_loss: 0.0866 - val_custom_loss: 0.0849\n",
      "Epoch 249/250\n",
      "108/110 [============================>.] - ETA: 0s - loss: -0.1031 - custom_loss: -0.1031\n",
      "Epoch 249: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1043 - custom_loss: -0.1043 - val_loss: 0.0512 - val_custom_loss: 0.0497\n",
      "Epoch 250/250\n",
      "109/110 [============================>.] - ETA: 0s - loss: -0.1086 - custom_loss: -0.1086\n",
      "Epoch 250: val_custom_loss did not improve from -0.02475\n",
      "110/110 [==============================] - 2s 15ms/step - loss: -0.1075 - custom_loss: -0.1075 - val_loss: 0.0378 - val_custom_loss: 0.0366\n"
     ]
    }
   ],
   "source": [
    "input_data = np.concatenate(((stack_scn/np.std(stack_scn,axis=1)[:,None]).reshape((len(stack_scn),600,1)),(stack_scn_flip/np.std(stack_scn,axis=1)[:,None]).reshape((len(stack_scn),600,1))))\n",
    "output_data = np.concatenate(((stack_sim).reshape((len(stack_sim),600,1)),(stack_sim_flip).reshape((len(stack_sim),600,1))))\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.33, random_state=42)\n",
    "ml = cnn(600)\n",
    "filepath = Output\n",
    "mc = ModelCheckpoint(filepath, verbose=1, monitor= 'val_custom_loss',save_best_only=True)\n",
    "history = ml.fit(X_train,y_train, epochs = num_epochs, batch_size = 8,verbose=1, validation_data = (X_test,y_test),callbacks=[mc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
